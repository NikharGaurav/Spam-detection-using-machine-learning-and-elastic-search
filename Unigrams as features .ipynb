{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from elasticsearch import Elasticsearch \n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import elasticsearch_dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es=Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_name='trec_spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query={\n",
    "    'query': \n",
    "    {'query_string': \n",
    "     {\"default_field\": \"split\",\n",
    "      \"query\": \"training\"\n",
    "     }\n",
    "    },\"size\": 75419}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = dict()\n",
    "word_dict = dict()\n",
    "res=es.search(index=index_name,doc_type='document',body=query)\n",
    "ids = [d['_id'] for d in res['hits']['hits']]\n",
    "for ID in ids:\n",
    "    body=es.get(index=index_name, doc_type='document', id=ID)['_source']['body']\n",
    "    text=re.sub(\" \\d+\", \" \", body)\n",
    "    text=text.replace('   ',' ')\n",
    "    text=text.replace('  ',' ')\n",
    "    terms = text.split()\n",
    "    for term in terms:\n",
    "        features[term]=term\n",
    "count=0\n",
    "for term in features:\n",
    "    count+=1\n",
    "    word_dict[term]=count\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_matrix_train=open('../sparse_matrix_train.txt','a')\n",
    "for ID in ids:\n",
    "    term_freq=dict()\n",
    "    label=es.get(index=index_name, doc_type='document',id=ID)['_source']['label']\n",
    "    if label=='spam':\n",
    "        ID_label='1'\n",
    "    else:\n",
    "        ID_label='0'\n",
    "    \n",
    "    body=es.get(index=index_name, doc_type='document',id=ID)['_source']['body']\n",
    "    text=re.sub(\" \\d+\", \" \", body)\n",
    "    text=text.replace('   ',' ')\n",
    "    text=text.replace('  ',' ')\n",
    "    \n",
    "    texts=text.split()\n",
    "    word_seq=dict()\n",
    "    for text in texts:\n",
    "        word_seq[str(text)]=word_dict[str(text)]\n",
    "        try:\n",
    "            term_freq[str(text)]+=1\n",
    "        except:\n",
    "            term_freq[str(text)]=1\n",
    "    \n",
    "    final=list()\n",
    "    check_word=dict()\n",
    "    \n",
    "    for word in sorted(word_seq, key=word_seq.get):\n",
    "        if word in check_word:\n",
    "            continue\n",
    "        else:\n",
    "            check_word[word]=word\n",
    "            final.append(str(word_dict[word]) + \":\" + str(term_freq[word]))\n",
    "            \n",
    "            \n",
    "    final_list=' '.join(final)\n",
    "    sparse_matrix_train.write(ID_label+\" \"+final_list+\"\\n\")\n",
    "sparse_matrix_train.close()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_matrix_test=open('../sparse_matrix_test.txt','a')\n",
    "test_query={\n",
    "    'query': \n",
    "    {'query_string': \n",
    "     {\"default_field\": \"split\",\n",
    "      \"query\": \"testing\"\n",
    "     }\n",
    "    },\"size\": 75419}\n",
    "test_res=es.search(index=index_name,doc_type='document',body=test_query)\n",
    "test_ids = [d['_id'] for d in test_res['hits']['hits']]\n",
    "\n",
    "for ID in test_ids:\n",
    "    term_freq=dict()\n",
    "    label=es.get(index=index_name, doc_type='document',id=ID)['_source']['label']\n",
    "    if label=='spam':\n",
    "        ID_label='1'\n",
    "    else:\n",
    "        ID_label='0'\n",
    "    \n",
    "    body=es.get(index=index_name, doc_type='document',id=ID)['_source']['body']\n",
    "    text=re.sub(\" \\d+\", \" \", body)\n",
    "    text=text.replace('   ',' ')\n",
    "    text=text.replace('  ',' ')\n",
    "    \n",
    "    texts=text.split()\n",
    "    word_seq=dict()\n",
    "    for text in texts:\n",
    "        try:\n",
    "            word_seq[str(text)]=word_dict[str(text)]\n",
    "            try:\n",
    "                term_freq[str(text)]+=1\n",
    "            except:\n",
    "                term_freq[str(text)]=1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    final=list()\n",
    "    check_word=dict()\n",
    "    \n",
    "    for word in sorted(word_seq, key=word_seq.get):\n",
    "        if word in check_word:\n",
    "            continue\n",
    "        else:\n",
    "            check_word[word]=word\n",
    "            final.append(str(word_dict[word]) + \":\" + str(term_freq[word]))\n",
    "            \n",
    "    final_list=' '.join(final)\n",
    "    sparse_matrix_test.write(ID_label+\" \"+final_list+\"\\n\")\n",
    "sparse_matrix_test.close()  \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from liblinearutil import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, x = svm_read_problem('../sparse_matrix/sparse_matrix_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test, x_test = svm_read_problem('../sparse_matrix_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob  = problem(y, x)\n",
    "param = parameter('-s 0 -c 4 -B 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.4753% (14855/15085) (classification)\n"
     ]
    }
   ],
   "source": [
    "m = train(prob, param)\n",
    "p_labels, p_acc, p_vals = predict(y_test, x_test, m,'-b 1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
